# Rationality
I like [Yudkowsky’s characterisation](https://www.lesswrong.com/posts/4ARtkT3EYox3THYjF/rationality-is-systematized-winning), which I will summarise as: epistemic rationality is about reliable belief formation and instrumental rationality is about effective action [1]. 

Often this means heavy deference to common sense, intuition, traditions, norms, authority; only rarely does it involve the arduous and hazardous task of “explicitly thinking things through for oneself”; perhaps never is it fully emotionless or articulate. 

Yudkowsky writes:

> There is a meme which says that a certain ritual of cognition is the paragon of /reasonableness/ and so defines what the /reasonable/ people do.  But alas, the /reasonable/ people often get their butts handed to them by the /unreasonable/ ones, because the universe isn’t always /reasonable/.  
> 
> Reason is just /a/ way of doing things, not necessarily /the/most  [formidable](https://www.lesswrong.com/lw/2c/a_sense_that_more_is_possible/) ; it is how professors talk to each other in debate halls, which sometimes works, and sometimes doesn’t.  If a hoard of barbarians attacks the debate hall, the truly prudent and flexible agent will abandon reasonableness.
> 
> […] Do not console yourself about how you were so wonderfully rational in the course of losing.  That is /not/ how things are supposed to go.  It is not the Art that fails, but you who fails to grasp the Art.

An important question: does rationality necessarily involve wanting what is good? As I understand it, rationality on the Kantian conception says “yes”, while rationality on the Humean naturalistic conception say “no”. I recently heard someone (Lucas Perry, I think) suggest that views on this question correspond with views on moral realism, which rings true to me.

An important point which should be obvious: rationality is not a binary property that minds either have or do not have, or that all humans share equally. It is a capability that can be cultivated, developed and refined over a lifetime, like other virtues.

Sadly, rationality is a loaded term with lots of confusing associations (c.f. [The Straw Vulcan](https://tvtropes.org/pmwiki/pmwiki.php/Main/StrawVulcan), rationalism in philosophy). I think “effective action” may be a better phrase to use than “instrumental rationality”; I’ll try it below.

Effective action is not about a particular method (e.g. checking judgements with explicit reasoning before acting; being wary of your intuitions; relying on heuristics). It involves awareness that there are many methods, and an ability to select those which are most appropriate to the situation. Often, especially for important decisions, it means bringing several methods to bear and using them to generate an overall judgement. A multi-method approach enables us to explore a broader range of solution space, then triangulate and cross-check solutions as we identify them. Sometimes, a solution that looks great from one perspective looks fatally flawed from another (e.g. XXX); other times, an extra perspective reveals a much cheaper solution than any of the others (e.g. XXX).

## Aside: Articulation, and “showing your work”
It’s important to keep in mind that epistemic and instrumental rationality always involves a great deal that is inarticulate, unspoken, intuitive, unconscious. Even with the most explicit and articulate methods, what is articulate is just the tip of the iceberg of cognitive process that leads to reasonable action. (I took Nick Chater’s “The Mind is Flat” course some years ago: so far as I understand his story, it is compatible with picture in this paragraph.)

Upshot: we should not assume that someone who acts rationally will be able to articulate their reasoning or otherwise “show their work”.

That said: willingness and ability to articulate reasons may correlate with effective action in at least some domains. I’m disturbingly unsure about how often this is true, though I’m also wary of romanticism on this point.

[1] The pragmatist in me wonders about the epistemic/instrumental distinction… can these really be teased apart? Insofar as they can, are there risks associated with doing so?  #todo


## Notes 
* I want to distinguish explicit articulation from reasoning. 
* The dual purpose of explicit articulation (social cognition, social cohesion) can be confusing.
	* If you’re mostly interested in cognition rather than cohesion you’re going to want to create an exceptionally “safe space” where people do not feel pressure to signal loyalty.
	* Maybe things get particularly hairy with moral philosophy, where it’s unclear whether we’re doing truth seeking or truth construction, and normative disagreement is reputationally high stakes.
* Bring in the CEO and press secretary stuff


<!-- #web/fragments -->

<!-- {BearID:rationality.md} -->
