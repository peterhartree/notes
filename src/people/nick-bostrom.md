# Nick Bostrom
Bostrom convinced me that reducing catastrophic and existential risks should be among our top global priorities. His thoughts on this are best introduced in [The Vulnerable World Hypothesis](https://nickbostrom.com/papers/vulnerable.pdf). Here’s an abstract from the abstract:

> Scientific and technological progress might change people’s capabilities or incentives in ways that would destabilize civilization. For example, advances in DIY biohacking tools might make it easy for anybody with basic training in biology to kill millions; novel military technologies could trigger arms races in which whoever strikes first has a decisive advantage; or some economically advantageous process may be invented that produces disastrous negative global externalities that are hard to regulate. This paper introduces the concept of a vulnerable world: roughly, one in which there is some level of technological development at which civilization almost certainly gets devastated by default, i.e. unless it has exited the ‘semi-anarchic default condition’. 

The paper begins:

> One way of looking at human creativity is as a process of pulling balls out of a giant urn. The balls represent possible ideas, discoveries, technological inventions. Over the course of history, we have extracted a great many balls – mostly white (beneﬁcial) but also various shades of gray (moderately harmful ones and mixed blessings). The cumulative effect on the human condition has so far been overwhelmingly positive, and may be much better still in the future (Bostrom, 2008). The global population has grown about three orders of magnitude over the last ten thousand years, and in the last two centuries per capita income, standards of living, and life expectancy have also risen. What we haven’t extracted, so far, is a black ball: a technology that invariably or by default destroys the civilization that invents it. The reason is not that we have been particularly careful or wise in our technology policy. We have just been lucky.

Bostrom has also originated or developed remarkably many other ideas that seem important, such as transhumanism, information hazards, the unilateralist curse and the parliamentary approach to moral uncertainty. 

On his website, he articulates a thought that has troubled me since my mid-teens:

> I believe it is likely that we are overlooking one or more crucial considerations: ideas or arguments that might plausibly reveal the need for not just some minor course adjustment in our endeavours but a major change of direction or priority. If we have overlooked even just one such crucial consideration, then all our best efforts might be for naught—or they might even be making things worse. 

Bostrom has dedicated his academic career to helping us discover and appreciate more crucial considerations for the future of humanity. I wish more of our best intellectuals would think in similarly ambitious terms.

Places to start:
* [Vulnerable World Hypothesis](https://nickbostrom.com/papers/vulnerable.pdf) (or [this podcast discussion](https://www.listennotes.com/podcasts/making-sense-with/151-will-we-destroy-the-future-OZju5zDEolh/))
* [Transhumanism FAQ](https://www.nickbostrom.com/views/transhumanist.pdf)
* [The Reversal Test: Eliminating Status Quo Bias in Applied Ethics](http://www.nickbostrom.com/ethics/statusquo.pdf)
* [Crucial Considerations](http://www.stafforini.com/blog/bostrom/)
* [NickBostrom.com](NickBostrom.com)

## Notes
* Add a longer list of favourite Bostrom papers, maybe with commentary.


<!-- #web/people -->


<!--stackedit_data:
eyJoaXN0b3J5IjpbMTE5NDk2MzcwMF19
-->

<!-- {BearID:nick-bostrom.md} -->
